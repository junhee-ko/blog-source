---
layout: post
title: "처리율 제한 장치 설계" 
date: 2023-09-03
categories: Design
---

네트워크 시스템에서 처리율 제한 장치 (rate limiter) 는 클라이언트 또는 서비스가 보내는 트래픽의 처리율을 제어하기 위한 장치다.
처리율 제한 장치를 두면,

1. Dos (Denial of Service) 공격에 의한 자원 고갈 (resource starvation) 을 방지
2. 비용 절감: 추가 요청에 대한 처리를 제한하면 서버를 많이 두지 않아도 되고, 우선 순위가 높은 API 에 더 많은 자원을 할당할 수 있다.
3. 서버 과부하 방지: bot 으로부터의 트래픽이나, 사용자의 잘못된 이용 패턴에 의한 트래픽을 필터링 할 수 있다.

이제, 처리율 제한 장치 설계해보자.

## 처리율 제한 장치를 어디에 둘 것인가

클라이언트 측이나 서버 측에 둘 수 있다.
클라이언트 측에 두는 것은 클라이언트의 요청은 쉽게 위변조가 가능하고, 모든 클라이언트의 구현을 통제하는 것이 어렵기 때문에 적절치 않다.

다른 방법으로, middleware 를 만들어서 해당 미들웨어로 하여금 API 서버로 가는 요청을 통제하는 것이다.
API 서버의 처리율이 초당 2개의 요청으로 제한된 상황에서, 클라이언트가 3번째 요청을 같은 초 범위 내에 전송했다고 하자.
그러면, 앞 두 요청은 API 서버로 전송이 되고 세 번째 요청은 처리율 제한 미들웨어에 의해 막혀 클라이언트에게 HTTP 상태코드 429 (too many requests) 가 반환된다.

클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 API gateway 라고 불리는 컴포넌트에 구현된다.
API gateway 는 아래 기능 등을 지원하는 fully managed, 즉 클라우드 업체가 유지 보수를 담당하는 서비스이다.

- 처리율 제한
- SSL 종단 (termination)
- 사용자 인증 (authenticaiton)
- IP whitelist 관리

## 처리율 제한 알고리즘

널리 알려진 알고리즘을오 다음과 같은 것들이 있다.

1. token bucket
2. leacky bucket
3. fixed window counter
4. sliding window log
5. sliding window counter

## 처리율 제한 규칙

처리율 제한 규칙들은 보통 configuration file 형태로 디스크에 저장된다.

```yaml
domain: messaging
descriptors:
  - key: message_type
    Value: marketing
    rate_limit:
      unit: day
      requests_per_unit: 5
```

## 처리율 한도 초과 트래픽 처리

어떤 요청이 한도 제한에 걸리면 API 는 다음의 HTTP 헤더와 함께 HTTP 429 응답을 클라이언트에게 보낸다.

- X-Ratelimit-Remaining: 윈도 내에 처리 가능한 요청의 수
- X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
- X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야하는지

경우에 따라, 한도 제한에 걸린 메세지를 나중에 처리하기 위해 큐에 보관할 수도 있다.

## 상세 설계

1. 처리율 제한 규칙을 디스크에 보관한다. 작업 프로세스 (workers) 는 수시로 규칙을 디스크에서 읽어 캐쉬에 저장한다.
2. 클라이언트가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어에 도달한다.
3. 처리율 제한 미들웨어는 제한 규칙을 캐쉬에서 읽어온다. 그리고, 카운터 및 마지막 요청의 timestamp 를 redis 에서 가져온다.
4. 이 값들에 근거해서, 해당 요청이 처리율 제한에 걸리지 않으면 API 서버로 보내고, 걸렸으면 429 에러를 클라이언트에게 보낸다.

## 분산 환경에서의 처리율 제한 장치

race condition 과 synchronization 문제를 해결해야한다.

### race condition

처리율 제한 장치는 다음과 같이 동작한다.

1. redis 에서 카운터의 값을 읽는다.
2. count + 1 값이 임계치는 넘는지 확인한다.
3. 넘지 않으면 redis 에 보관된 카운터의 값을 1 증가시킨다.

병렬 처리하는 상황에서는 경쟁 조건 이슈가 발생한다.

1. redis 에 저장된 카운터의 값이 3 이라고 하자.
2. 두 개 요청을 처리하는 스레드가 각각 병렬로 카운터 값을 읽었고, 각각 카운터에 1을 더한 값을 redis 에 기록할 것이다.
3. 카운터 값이 5가 되어야하는데, 4로 기록되는 문제가 발생한다.

lock 을 이용하면 이 문제를 해결할 수 있지만, 시스템 성능을 떨어뜨리는 문제가 있다.
다른 방법으로, lua script 나 redis 의 sorted set 자료구조를 사용해서 해결할 수도 있다.

### synchronization

클라이언트의 요청이 각기 다른 처리율 제한 장치로 보내질 수 있기 때문에, 처리율 제한 장치 서버를 여러 대 두면 동기화가 필요해진다.
이 문제를 해결하기 위해, sticky session 을 활용해서 같은 클라이언트 요청이 항상 같은 처리율 제한 장치로 보낼 수 있도록 할 수 있다. 
하지만, 규묘면에서 확장 가능하지도 않고 유연하지 않다. 

그래서, redis 같은 중앙 집중형 데이터 저장소를 활용할 수도 있다. 

---

System Design Interview <알렉스 쉬>
